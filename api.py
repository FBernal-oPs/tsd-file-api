
""" API to support file uploads into TSD projects via the proxy. """

import sys
import jwt # https://github.com/davedoesdev/python-jwt
import os
import yaml
import psycopg2
import psycopg2.pool
import time
import datetime
import flask
from flask import Flask, request, redirect, url_for, jsonify, g
from werkzeug.utils import secure_filename
from flask import send_from_directory
from werkzeug.formparser import FormDataParser
from collections import OrderedDict


# add method for handling PGP encrypted files
FormDataParser.parse_functions['multipart/encrypted'] = FormDataParser._parse_multipart

def read_config(file):
    with open(file) as f:
        conf = yaml.load(f)
    return conf


CONF = read_config(sys.argv[1])
UPLOAD_FOLDER = CONF['file_uploads']
JWT_SECRET = CONF['jwt_secret']
ALLOWED_EXTENSIONS = set(['txt', 'pdf', 'png', 'jpg', 'jpeg', 'csv', 'tsv', 'asc'])
MINCONN = 4
MAXCONN = 10
pool = psycopg2.pool.SimpleConnectionPool(MINCONN, MAXCONN, \
    host=CONF['host'], database=CONF['db'], user=CONF['user'], password=CONF['pw'])
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024


def get_dbconn():
    dbconn = getattr(g, 'dbconn', None)
    if dbconn is None:
        conn = pool.getconn()
        dbconn = g.dbconn = conn
    return dbconn


@app.teardown_appcontext
def close_connection(exception):
    dbconn = getattr(g, 'dbconn', None)
    if dbconn is not None:
        dbconn.close()


@app.route('/upload_signup', methods=['GET', 'POST'])
def upload_signup():
    """Create a user, password entry that could allow a user to _upload_ files.
    This user must first be verified by a TSD admin before being allowed to request
    access tokens.
    """
    data = request.get_json()
    get_dbconn()
    cur = g.dbconn.cursor()
    cur.execute("select public.signup(%s, %s)", (data['email'], data['pass']))
    g.dbconn.commit()
    return jsonify({'message': 'signed up for file uploads'}), 201


@app.route('/download_signup', methods=['GET', 'POST'])
def download_signup():
    """Create a user, password entry that could allow a user to _download_ files.
    This user must first be verified by a TSD admin before being allowed to request
    access tokens. This is a much more stringent authentication process involving SAML
    integration with id-porten.
    """
    data = request.get_json()
    get_dbconn()
    cur = g.dbconn.cursor()
    cur.execute("select reports.signup(%s, %s)", (data['external_user_id'], data['user_group']))
    g.dbconn.commit()
    return jsonify({'message': 'signed up for file downloads'}), 201


@app.route('/upload_token', methods=['GET', 'POST'])
def get_upload_token():
    """Get a JWT that allows _uploading_ files. These tokens are the same as those
    generated by the storage API. The implication is that if you have permission
    to upload files then you have permission to upload json data and vice versa.
    If the storage/retrieval APIs are deployed in the TSD project then these
    app routes are not strictly necessary, but having them enables the deployment
    of the file-api as a standalone component (along with the postgresql db).
    """
    data = request.get_json()
    get_dbconn()
    cur = g.dbconn.cursor()
    cur.execute("select public.token(%s, %s)", (data['email'], data['pass']))
    res = cur.fetchall()
    token = res[0][0]
    return jsonify([{ 'token': token }]), 200


@app.route('/download_token', methods=['GET', 'POST'])
def get_download_token(saml_data):
    """Get a JWT that allows _downloading_ files.These tokens are the same as those
    generated by the retrieval API. The implication is that if you have permission
    to download files then you have permission to download json data and vice versa.
    If the storage/retrieval APIs are deployed in the TSD project then these
    app routes are not strictly necessary, but having them enables the deployment
    of the file-api as a standalone component (along with the postgresql db).
    """
    data = request.get_json()
    get_dbconn()
    cur = g.dbconn.cursor()
    cur.execute("select reports.token(%s)", (data['saml_data']))
    res = cur.fetchall()
    token = res[0][0]
    return jsonify([{ 'token': token }]), 200


def verify_json_web_token(request_headers, required_role=None, timeout=None):
    """Verifies the authenticity of API credentials, as stored in a JSON Web Token
    (see jwt.io for more).

    Details:
    0) Checks for the existence of a token
    1) Checks the cryptographic integrity of the token - that it was obtained from an
    authoritative source with access to the secret key
    2) Extracts the JWT header and the claims
    3) Checks that the role assigned to the user in the db is allowed to perform the action
    4) Checks that the token has not expired - 1 hour is the current lifetime
    """
    try:
        token = request.headers['Authorization'].replace('Bearer ', '')
        header, claims = jwt.verify_jwt(token, JWT_SECRET, ['HS256'], checks_optional=True)
    except KeyError:
        return jsonify({'message': 'No JWT provided.'}), 400
    except jwt.jws.SignatureError:
        return jsonify({'message': 'Access forbidden - Unable to verify signature.'}), 403
    if claims['role'] != required_role:
        return jsonify({'message': 'Access forbidden - Your role does not allow this operation.'}), 403
    cutoff_time = int(time.time()) + timeout
    if int(claims['exp']) > cutoff_time:
        return jsonify({'message': 'Access forbidden - JWT expired.'}), 403
    else:
        return True


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1] in ALLOWED_EXTENSIONS


@app.route('/upload', methods=['POST', 'PUT'])
def upload_file():
    """Allows authenticated and authorized users to upload a file. Current max size is 40MB.
    All files are saved to the same directory.

    Content-Types:
    - For plain text ->             'Content-Type: multipart/form-data'
    - For PGP encrypted text use -> 'Content-Type: multipart/encrypted; protocol="pgp-encrypted"'

    Initiating actions after file uploads (not implemented yet):
    - request.mimetype - this is e.g. multipart/encrypted
    - request.mimetype_params - includes protocol, boundary
    - after saving file, if mimetype multipart/encrypted
        - do something with it, like decrypt it
        - perhaps only if we also get another custom header, like e.g. X-Decrypt
    """
    print request.headers
    status = verify_json_web_token(request.headers, required_role='app_user', timeout=(60*60*24))
    if status is not True:
        return status
    if request.method == 'POST':
        if 'file' not in request.files:
            return jsonify({'message': 'file not found'}), 400
        file = request.files['file']
        if file.filename == '':
            return jsonify({'message': 'no filename specified'}), 400
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
            return jsonify({'message': 'uploaded file'}), 201
        else:
            return jsonify({'message': 'file type not allowed'}), 400


@app.route('/stream', methods=['POST', 'PATCH'])
def upload_file_stream():
    """This endpoint support uploading files as a binary stream,
    using 'Content-Type: application/octet-stream'.

    Incoming request data are written to a file byte-for-byte, in order.
    No data processing is done. All incoming bytes are preserved and written to a file as is.
    If a file is being streamed, for example, it is the client's responsibilty to construct
    the binary stream correctly, so that when the bytes are written to the file, data integrity
    will be preserved.

    Cliets should provide a file name in a custom header: 'X-Filename: <filename>'. If no filename
    is provided the current ISO 8601 timestamp will be chosen.

    Nginx sets the maximum Content-Length allowed for the stream on a per request basis. If the
    data stream is smaller than the maximum Content-Length then a file can be streamed using POST:

    curl -X POST --data-binary @file -H 'Content-Type: application/octet-stream' \
        -H 'X-Filename: filename' http://url/stream

    If the data stream exceeds maximum Content-Length then data can be sent in consecutive
    streams, in separate requests. Incoming streams are appended to each other, byte-for-byte.
    Suppose a large file is split into two files (file1 and file2), clients can send streams
    to the same file using PATCH:

    curl -X PATCH --data-binary @file1 -H 'Content-Type: application/octet-stream' \
        -H 'X-Filename: filename' http://url/stream

    curl -X PATCH --data-binary @file2 -H 'Content-Type: application/octet-stream' \
        -H 'X-Filename: filename' http://url/stream

    In this case the filename _must_ be provided, otherwise the streams will end up in separate
    files.
    """
    storage_token_status = verify_json_web_token(request.headers, required_role='app_user', timeout=(60*60*24))
    try:
        supplied_file_name = request.headers['X-Filename']
    except KeyError:
        supplied_file_name = datetime.datetime.now().isoformat() + '.txt'
    filename = os.path.normpath(app.config['UPLOAD_FOLDER'] + '/' + supplied_file_name)
    if request.method == 'POST':
        file_mode = 'wb+'
    elif request.method == 'PATCH':
        file_mode = 'ab+'
    with open(filename, file_mode) as f:
        chunk_size = 4096
        while True:
            chunk = flask.request.stream.read(chunk_size)
            if len(chunk) == 0:
                return jsonify({'message': 'file uploaded'}), 201
            f.write(chunk)
    return jsonify({'message': 'file uploaded'}), 201


@app.route('/list', methods=['GET'])
def list_files():
    """This is not sensitive data per se, so storage API tokens can be used; so can the retrieval API token.
    Returns a list of files in the uploaded folder, and the time of last modification.
    """
    storage_token_status = verify_json_web_token(request.headers, required_role='app_user', timeout=(60*60*24))
    retrieval_token_status = verify_json_web_token(request.headers, required_role='full_access_reports_user', timeout=(60*60))
    if (storage_token_status or retrieval_token_status) is not True:
        return status
    dir = app.config['UPLOAD_FOLDER']
    files = os.listdir(dir)
    times = map(lambda x: datetime.datetime.fromtimestamp(os.stat(os.path.normpath(dir+'/'+x)).st_mtime).isoformat(), files)
    file_info = OrderedDict()
    for i in zip(files, times):
        file_info[i[0]] = i[1]
    return jsonify(file_info), 200


@app.route('/download/<filename>', methods=['GET'])
def download_file(filename):
    """Allows authenticated and authorized users to download a file.
    """
    status = verify_json_web_token(request.headers, required_role='full_access_reports_user', timeout=(60*60))
    if status is not True:
        return status
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)


# should not have debug in prod
if __name__ == '__main__':
    app.run(host='0.0.0.0', debug=True)
